# Staging Models

Auto-generated dbt models that clean and deduplicate raw data.

---

## Overview

Staging models are the first transformation layer in Dango. They take raw data loaded by dlt and prepare it for downstream analytics by:

- Deduplicating records
- Renaming columns to SQL-friendly names
- Casting data types
- Selecting relevant columns
- Preserving dlt metadata for lineage

**Key Points**:

- Auto-generated by `dango generate`
- Materialized as views (no storage overhead)
- One staging model per raw table
- Follow dbt naming conventions (`stg_<source>_<table>`)

---

## Quick Start

### Generate Staging Models

After loading data with `dango sync`:

```bash
# Load raw data
dango sync --source stripe_payments

# Auto-generate staging models
dango generate

# Run transformations
dango run
```

This creates:

```
dbt/models/staging/
├── stg_stripe_charges.sql
├── stg_stripe_customers.sql
├── stg_stripe_subscriptions.sql
├── _stg_stripe__sources.yml
└── _stg_stripe__schema.yml
```

---

## Generated File Structure

### SQL Models

Each raw table gets a corresponding staging model:

```sql
-- dbt/models/staging/stg_stripe_charges.sql
{{ config(
    materialized='view',
    schema='staging'
) }}

WITH source AS (
    SELECT * FROM {{ source('stripe', 'charges') }}
),

deduplicated AS (
    SELECT *,
        ROW_NUMBER() OVER (
            PARTITION BY id
            ORDER BY _dlt_extracted_at DESC
        ) as _rn
    FROM source
)

SELECT
    -- Primary key
    id,

    -- Foreign keys
    customer,
    payment_intent,

    -- Attributes
    amount,
    currency,
    status,
    description,
    created,

    -- dlt metadata
    _dlt_load_id,
    _dlt_extracted_at

FROM deduplicated
WHERE _rn = 1
```

### Sources Configuration

`_stg_<source>__sources.yml` defines raw table references:

```yaml
version: 2

sources:
  - name: stripe
    description: Stripe payment data loaded via dlt
    schema: raw_stripe
    loaded_at_field: _dlt_extracted_at

    tables:
      - name: charges
        description: Payment charges from Stripe API

      - name: customers
        description: Customer records from Stripe API

      - name: subscriptions
        description: Subscription records from Stripe API
```

### Schema Documentation

`_stg_<source>__schema.yml` documents staging models:

```yaml
version: 2

models:
  - name: stg_stripe_charges
    description: Stripe charges deduplicated and cleaned
    columns:
      - name: id
        description: Unique charge ID
        tests:
          - unique
          - not_null

      - name: customer
        description: Customer ID reference

      - name: amount
        description: Charge amount in cents
        tests:
          - not_null

      - name: status
        description: Charge status (succeeded, failed, pending)
        tests:
          - accepted_values:
              values: ['succeeded', 'failed', 'pending']
```

---

## How Generation Works

### 1. Scan Raw Layer

`dango generate` inspects DuckDB for raw tables:

```sql
-- Finds all tables in raw schemas
SELECT
    table_schema,
    table_name
FROM information_schema.tables
WHERE table_schema LIKE 'raw%'
```

### 2. Analyze Schema

For each table, examines:

- Column names and types
- Primary key patterns (usually `id`)
- Foreign key patterns (columns ending in `_id`)
- dlt metadata columns

### 3. Apply Deduplication Strategy

Based on source configuration in `.dango/sources.yml`:

```yaml
sources:
  - name: stripe_payments
    type: stripe
    deduplication:
      strategy: latest  # Options: latest, merge, none
      partition_key: id
      order_key: _dlt_extracted_at
```

**Strategies**:

| Strategy | Behavior | Use Case |
|----------|----------|----------|
| `latest` | Keep most recent record | Mutable data (customers, products) |
| `merge` | Combine overlapping records | Complex updates |
| `none` | No deduplication | Append-only logs |

### 4. Generate SQL

Creates dbt models following best practices:

- CTEs for readability
- Explicit column selection
- Data type casting where needed
- Preserved dlt metadata

---

## Materialization Strategy

### Views (Default)

Staging models use `materialized='view'`:

```sql
{{ config(materialized='view') }}
```

**Benefits**:

- No storage overhead
- Always reflects raw data
- Fast to rebuild
- Cheap to maintain

**When to change to table**:

- Large raw tables (millions of rows)
- Complex deduplication logic
- Performance issues in downstream models

```sql
{{ config(materialized='table') }}
```

---

## Deduplication Patterns

### Latest Record (Default)

Most common pattern for mutable data:

```sql
WITH deduplicated AS (
    SELECT *,
        ROW_NUMBER() OVER (
            PARTITION BY id
            ORDER BY _dlt_extracted_at DESC
        ) as _rn
    FROM {{ source('stripe', 'customers') }}
)

SELECT * FROM deduplicated
WHERE _rn = 1
```

This keeps the most recently extracted version of each record.

### Merge Strategy

For complex update scenarios:

```sql
WITH base AS (
    SELECT * FROM {{ source('stripe', 'subscriptions') }}
),

latest_per_key AS (
    SELECT *,
        ROW_NUMBER() OVER (
            PARTITION BY id, _dlt_load_id
            ORDER BY _dlt_extracted_at DESC
        ) as _rn
    FROM base
),

merged AS (
    SELECT
        id,
        COALESCE(updated_field, original_field) as field,
        -- Merge logic here
    FROM latest_per_key
    WHERE _rn = 1
)

SELECT * FROM merged
```

### No Deduplication

For append-only event logs:

```sql
SELECT
    id,
    event_type,
    timestamp,
    user_id,
    _dlt_load_id,
    _dlt_extracted_at
FROM {{ source('analytics', 'events') }}
-- No deduplication - every event is unique
```

---

## Column Naming Conventions

Dango follows dbt best practices:

### Renamed Columns

```sql
SELECT
    id,
    customer as customer_id,           -- Add _id suffix
    amount_cents as amount,             -- Remove redundant suffixes
    created as created_at,              -- Standardize timestamp names
    is_deleted as deleted_flag          -- Boolean clarity
FROM {{ source('stripe', 'charges') }}
```

### Reserved Names

Avoid SQL keywords:

```sql
-- Bad (reserved keyword)
"order" as order,

-- Good
"order" as order_id,
```

### Standardized Timestamps

```sql
SELECT
    created as created_at,
    updated as updated_at,
    deleted as deleted_at
```

---

## Working with Generated Models

### Don't Modify Generated Files

Generated staging models are **overwritten** on each `dango generate`. Instead:

**Bad**:
```sql
-- DON'T edit dbt/models/staging/stg_stripe_charges.sql
SELECT
    id,
    amount / 100.0 as amount_usd  -- Will be lost on regeneration
FROM {{ source('stripe', 'charges') }}
```

**Good**:
```sql
-- Create dbt/models/intermediate/int_stripe_charges_usd.sql
SELECT
    id,
    amount / 100.0 as amount_usd
FROM {{ ref('stg_stripe_charges') }}
```

### Add Custom Logic in Intermediate

For source-specific transformations:

```sql
-- dbt/models/intermediate/int_stripe_charges_enriched.sql
{{ config(materialized='view') }}

SELECT
    c.*,
    -- Custom business logic
    CASE
        WHEN c.amount >= 100000 THEN 'enterprise'
        WHEN c.amount >= 10000 THEN 'professional'
        ELSE 'starter'
    END as customer_tier,

    -- Convert cents to dollars
    c.amount / 100.0 as amount_usd,

    -- Extract date parts
    DATE_TRUNC('month', c.created) as month,
    EXTRACT(year FROM c.created) as year

FROM {{ ref('stg_stripe_charges') }} c
WHERE c.status = 'succeeded'
```

---

## Regeneration Workflow

### When to Regenerate

Run `dango generate` when:

1. **New source added** - Creates staging for new tables
2. **Schema changed** - Updates column selections
3. **Deduplication strategy changed** - Modifies SQL logic
4. **dlt loads new tables** - Discovers additional resources

### Safe Regeneration

```bash
# 1. Backup custom changes (if any)
git status

# 2. Regenerate staging
dango generate

# 3. Review changes
git diff dbt/models/staging/

# 4. Run transformations
dango run

# 5. Test
dbt test --select staging.*
```

### Selective Generation

Generate for specific source:

```bash
# Only regenerate Stripe staging models
dango generate --source stripe_payments
```

---

## Testing Staging Models

### Auto-generated Tests

Schema YAML includes basic tests:

```yaml
models:
  - name: stg_stripe_charges
    columns:
      - name: id
        tests:
          - unique        # No duplicate IDs
          - not_null      # ID always present
```

Run tests:

```bash
# Test all staging models
dbt test --select staging.*

# Test specific model
dbt test --select stg_stripe_charges
```

### Add Custom Tests

Extend `_stg_<source>__schema.yml`:

```yaml
models:
  - name: stg_stripe_charges
    columns:
      - name: amount
        tests:
          - not_null
          - dbt_utils.expression_is_true:
              expression: ">= 0"  # Amount never negative

      - name: currency
        tests:
          - accepted_values:
              values: ['usd', 'eur', 'gbp']
```

---

## Advanced Patterns

### Multi-Source Staging

When same entity comes from multiple sources:

```sql
-- dbt/models/staging/stg_all_customers.sql
{{ config(materialized='view') }}

SELECT
    'stripe' as source,
    id as customer_id,
    email,
    created_at
FROM {{ ref('stg_stripe_customers') }}

UNION ALL

SELECT
    'hubspot' as source,
    id as customer_id,
    email,
    created_at
FROM {{ ref('stg_hubspot_contacts') }}
```

### Incremental Staging

For very large tables:

```sql
{{ config(
    materialized='incremental',
    unique_key='id',
    on_schema_change='append_new_columns'
) }}

SELECT
    id,
    event_type,
    timestamp,
    _dlt_extracted_at
FROM {{ source('analytics', 'events') }}

{% if is_incremental() %}
WHERE _dlt_extracted_at > (SELECT MAX(_dlt_extracted_at) FROM {{ this }})
{% endif %}
```

### Conditional Column Selection

Based on table structure:

```sql
SELECT
    id,
    {% if 'email' in columns %}
    email,
    {% endif %}
    {% if 'phone' in columns %}
    phone,
    {% endif %}
    created_at
FROM {{ source('crm', 'contacts') }}
```

---

## Troubleshooting

### Generation Fails

**Problem**: `dango generate` errors or skips tables

**Solutions**:

1. **Check raw data exists**:
   ```bash
   duckdb data/warehouse.duckdb "SHOW TABLES;"
   ```

2. **Verify source configuration**:
   ```bash
   dango source list
   ```

3. **Check permissions**:
   ```bash
   ls -la dbt/models/staging/
   ```

### Deduplication Not Working

**Problem**: Duplicate records in staging

**Check**:

1. **Partition key is correct**:
   ```sql
   -- Find actual primary key
   SELECT id, COUNT(*)
   FROM raw_stripe.charges
   GROUP BY id
   HAVING COUNT(*) > 1;
   ```

2. **Order key has values**:
   ```sql
   SELECT COUNT(*)
   FROM raw_stripe.charges
   WHERE _dlt_extracted_at IS NULL;
   ```

### Performance Issues

**Problem**: Staging models slow to query

**Solutions**:

1. **Materialize as table**:
   ```sql
   {{ config(materialized='table') }}
   ```

2. **Add filters in sources.yml**:
   ```yaml
   sources:
     - name: stripe
       stripe:
         start_date: 2024-01-01  # Limit historical data
   ```

3. **Use incremental**:
   ```sql
   {{ config(materialized='incremental') }}
   ```

---

## Best Practices

### 1. Keep Staging Simple

Staging should only:

- Select columns
- Rename columns
- Cast types
- Deduplicate

**Don't** add business logic:

```sql
-- Bad - business logic in staging
SELECT
    id,
    CASE WHEN amount > 1000 THEN 'high_value' ELSE 'standard' END as tier
FROM {{ source('stripe', 'charges') }}

-- Good - staging stays simple
SELECT
    id,
    amount
FROM {{ source('stripe', 'charges') }}
```

### 2. Preserve dlt Metadata

Always keep dlt columns:

```sql
SELECT
    -- Business columns
    id,
    email,
    created,

    -- dlt metadata (important for debugging)
    _dlt_load_id,
    _dlt_extracted_at
FROM {{ source('stripe', 'customers') }}
```

### 3. Document Column Mappings

When renaming:

```yaml
models:
  - name: stg_stripe_charges
    columns:
      - name: customer_id
        description: "Stripe customer ID (renamed from 'customer')"
```

### 4. Test Primary Keys

Always test uniqueness:

```yaml
columns:
  - name: id
    tests:
      - unique
      - not_null
```

### 5. Version Control Schema Files

Commit generated YAML to track schema changes:

```bash
git add dbt/models/staging/_stg_*__schema.yml
git commit -m "Update staging schema for Stripe"
```

---

## Comparison: Staging vs. Intermediate vs. Marts

| Aspect | Staging | Intermediate | Marts |
|--------|---------|--------------|-------|
| **Purpose** | Clean raw data | Reusable logic | Final metrics |
| **Generated** | Yes (auto) | No (custom) | No (custom) |
| **Materialization** | View | View/Table | Table |
| **Complexity** | Simple | Medium | Complex |
| **Business Logic** | None | Some | Full |
| **Dependencies** | Raw tables | Staging | Intermediate |

---

## Reference: Generated SQL Template

Dango uses this template for staging models:

```sql
{{ config(
    materialized='view',
    schema='staging'
) }}

{# Load source data #}
WITH source AS (
    SELECT * FROM {{ source('<source_name>', '<table_name>') }}
),

{# Apply deduplication if configured #}
{% if deduplication_strategy == 'latest' %}
deduplicated AS (
    SELECT *,
        ROW_NUMBER() OVER (
            PARTITION BY {{ partition_key }}
            ORDER BY {{ order_key }} DESC
        ) as _rn
    FROM source
)
{% else %}
deduplicated AS (
    SELECT * FROM source
)
{% endif %}

{# Select and rename columns #}
SELECT
    -- Primary key
    {{ primary_key }},

    -- Foreign keys
    {% for fk in foreign_keys %}
    {{ fk }},
    {% endfor %}

    -- Attributes
    {% for col in attributes %}
    {{ col }},
    {% endfor %}

    -- Metadata
    _dlt_load_id,
    _dlt_extracted_at

FROM deduplicated
{% if deduplication_strategy == 'latest' %}
WHERE _rn = 1
{% endif %}
```

---

## Next Steps

- **[Custom Models](custom-models.md)** - Build marts and intermediate layers
- **[Testing](testing.md)** - Comprehensive data quality testing
- **[dbt Basics](dbt-basics.md)** - Learn dbt fundamentals
- **[Data Layers](../core-concepts/data-layers.md)** - Understand the full architecture
